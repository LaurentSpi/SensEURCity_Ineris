sensdata <- as.data.frame(sensdata)
sensdata2 <- subset(sensdata, select = setdiff(names(sensdata), c("datetime", "Typology")))
sensdata2$ID=as.character(sensdata2$ID)
sensdata2$Location.ID=as.character(sensdata2$Location.ID)
sensdata2$PM2.5=as.numeric(sensdata2$PM2.5)
sensdata2 = aggregate(. ~ ID + Location.ID, sensdata2, function(x) mean(x, na.rm=TRUE), na.action = na.pass)
rownames(sensdata2) = sensdata2$ID
nbr_sensor = nrow(sensdata2)
typology_sens <- sensdata %>%
dplyr::select(ID, Location.ID, Typology) %>%
dplyr::distinct(ID, Location.ID, Typology)
typology_sens[which(typology_sens$Location.ID=="ANT_URB_KIPD"),3]<-"URB"
save(typology_sens, file = file_typology_sens_Rda)
sensdata2 <- left_join(sensdata2, typology_sens, by = c("ID", "Location.ID"))
# Define start and end date
start_date <- min(stadata$date) # starting date
end_date <-max(stadata$date) # ending date
sensdata3 <- sensdata2
sensdata3$Category <- "dedicated"
# Capteurs "colocated"
colocated_ids <- paste0("Antwerp_", c("4065EA", "4067BD", "4067B3", "40642B", "4047D7", "4065DA"))
sensdata3$Category[sensdata3$ID %in% colocated_ids] <- "colocated"
# Capteurs "duplicated-colocated"
duplicated_colocated_ids <- paste0("Antwerp_", c("40499F", "4043AE", "4049A6", "4043A7", "40499C", "4043B1"))
sensdata3$Category[sensdata3$ID %in% duplicated_colocated_ids] <- "duplicated-colocated"
# sensdata3 en un sf object
spsensdata3_sf <- st_as_sf(sensdata3, coords = c("X", "Y"), crs = CRS_BELG)
spsensdata3_sf <- st_transform(spsensdata3_sf, crs = 4326)
# coordonnées pour leaflet
coords <- st_coordinates(spsensdata3_sf)
spsensdata3_sf$lon <- coords[, 1]
spsensdata3_sf$lat <- coords[, 2]
# carte interactive
colors <- colorFactor(palette = c("darkblue", "darkred", "darkgreen"), domain = spsensdata3_sf$Typology)
m_typo <- leaflet() %>%
addTiles() %>%
addCircleMarkers(data = spsensdata3_sf, ~lon, ~lat, popup = ~as.character(Typology),
color = ~colors(Typology), fill = TRUE, radius = 5) %>%
addControl(html = "
<div style='background: white; padding: 10px;'>
<h4>Typology</h4>
<div style='display: flex; align-items: center;'>
<div style='width: 15px; height: 15px; background: darkblue; margin-right: 5px;'></div>
URB
</div>
<div style='display: flex; align-items: center;'>
<div style='width: 15px; height: 15px; background: darkred; margin-right: 5px;'></div>
TRA
</div>
<div style='display: flex; align-items: center;'>
<div style='width: 15px; height: 15px; background: darkgreen; margin-right: 5px;'></div>
INDUS
</div>
</div>",
position = "bottomright")
m_typo
mapshot(m_typo, file = file.path(path_figures_general, "03Map_Antwerp_Sensors_v2.png"))
# carte
pal <- colorFactor(palette = c("blue", "red", "darkgreen"),
domain = c("dedicated", "colocated", "duplicated-colocated"))
m_category <- leaflet(spsensdata3_sf) %>%
addTiles() %>%
addCircleMarkers(~lon, ~lat, color = ~pal(Category),
popup = ~paste("ID:", ID, "<br>Category:", Category)) %>%
addLegend("bottomright", pal = pal, values = ~Category, title = "Sensor Category")
m_category
mapshot(m_category, file = file.path(path_figures_general, "03Map_Antwerp_Sensors_Category.png"))
spsensdata2clust <- sensdata2
coordinates(spsensdata2clust)=~X+Y
proj4string(spsensdata2clust)=CRS_BELG
class(spsensdata2clust); summary(spsensdata2clust)
# Convertir le data frame sensdata2 en un sf
spsensdata2clust_sf <- st_as_sf(spsensdata2clust, coords = c("X", "Y"), crs = CRS_BELG)
spsensdata2clust_sf <- st_transform(spsensdata2clust_sf, crs = 4326)
coords <- st_coordinates(spsensdata2clust_sf)
spsensdata2clust_sf$lon <- coords[, 1]
spsensdata2clust_sf$lat <- coords[, 2]
# Look for clusters
chc <- hclust(dist(data.frame(rownames=rownames(spsensdata2clust@data), x=coordinates(spsensdata2clust)[,1],
y=coordinates(spsensdata2clust)[,2])), method="complete")
chc.d50 <- cutree(chc, h=50)
spsensdata2clust@data <- data.frame(spsensdata2clust@data, Clust=chc.d50)
spsensdata2clust_sf$Clust <- as.factor(chc.d50)  # Convert clusters to factor for coloring
nb.cols <- max(spsensdata2clust@data$Clust)
mycolors <- colorRampPalette(brewer.pal(8, "Dark2"))(nb.cols)
pal_cluster <- colorFactor(palette = mycolors, domain = spsensdata2clust_sf$Clust)
m_cluster <- leaflet(spsensdata2clust_sf) %>%
addTiles() %>%
addCircleMarkers(~lon, ~lat, color = ~pal_cluster(Clust), radius = 5, fillOpacity = 0.7) %>%
addLegend("bottomright", pal = pal_cluster, values = ~Clust, title = "SensorClusters")
m_cluster
mapshot(m_cluster, file = file.path(path_figures_general, "03Map_Antwerp_Sensor_Clusters.png"))
df_clusters=as.data.frame(spsensdata2clust)
sensdata_wtypo_corr_cluster = as.data.frame(spsensdata2clust)
sensdata_wtypo_corr_cluster = subset(sensdata_wtypo_corr_cluster,select=-c(X,Y,PM2.5,Typology,Location.ID))
sensdata_wtypo_corr_cluster2=sensdata_wtypo_corr_cluster
sensdata_wtypo_corr_cluster2 = subset(sensdata_wtypo_corr_cluster2,select=-c(ID))
sensdata_wtypo_corr_cluster2$Count=rep(1,length(sensdata_wtypo_corr_cluster2[,1]))
stat_clust = aggregate(. ~ Clust, sensdata_wtypo_corr_cluster2, function(x) sum(x, na.rm=TRUE), na.action = na.pass)
stat_clust = subset(stat_clust,select=c(Clust,Count))
clust2out = which(stat_clust$Count > 10)
sensdataf2=merge(sensdata,sensdata_wtypo_corr_cluster,by=c("ID"))
winter_start = as.POSIXct("2020-12-01 00:00:00", tz="UTC")
winter_end = as.POSIXct("2021-02-28 23:59:59", tz="UTC")
# Spring (MAM)
spring_start = as.POSIXct("2021-03-01 00:00:00", tz="UTC")
spring_end = as.POSIXct("2021-05-31 23:59:59", tz="UTC")
# Summer (JJA)
summer_start = as.POSIXct("2020-06-01 00:00:00", tz="UTC")
summer_end = as.POSIXct("2020-08-31 23:59:59", tz="UTC")
# Fall (SON)
fall_start = as.POSIXct("2020-09-01 00:00:00", tz="UTC")
fall_end = as.POSIXct("2020-11-30 23:59:59", tz="UTC")
# Créer une nouvelle colonne 'Season' avec une valeur par défaut
sensdataff<-sensdataf2
sensdataff$Season <- "no season"
# Assigner les saisons
sensdataff$Season[which(sensdataff$datetime >= winter_start & sensdataff$datetime <= winter_end)] <- "Winter"
sensdataff$Season[which(sensdataff$datetime >= spring_start & sensdataff$datetime <= spring_end)] <- "Spring"
sensdataff$Season[which(sensdataff$datetime >= summer_start & sensdataff$datetime <= summer_end)] <- "Summer"
sensdataff$Season[which(sensdataff$datetime >= fall_start & sensdataff$datetime <= fall_end)] <- "Fall"
Weekdays <- rep("weekdays",length(sensdataff[,1]))
sensdataff$Weekdays=Weekdays
sensdataff$Weekdays=weekdays(as.POSIXct(sensdataff$datetime), abbreviate = F)
DayType <- rep("Weekday",length(sensdataff[,1]))
sensdataff$DayType=DayType
sensdataff[which(sensdataff$Weekdays == "samedi" | sensdataff$Weekdays == "dimanche"),11]<-"Weekend"
sensdataff$Hour=as.numeric(format(sensdataff$datetime, format = "%H"))
Periods <- rep("periods",length(sensdataff[,1]))
sensdataff$Periods=Periods
sensdataff[which(sensdataff$Hour > 6 & sensdataff$Hour <= 9 | sensdataff$Hour > 16 & sensdataff$Hour <= 20),13]<-"Traffic hours"
sensdataff[which(sensdataff$Hour > 9 & sensdataff$Hour <= 16 | sensdataff$Hour > 20 & sensdataff$Hour <= 22),13]<-"Off-peak hours"
sensdataff[which(sensdataff$Hour > 22 | sensdataff$Hour == 0 | sensdataff$Hour > 5 & sensdataff$Hour <= 6),13]<-"Transition periods"
sensdataff[which(sensdataff$Hour >= 1 & sensdataff$Hour <= 5),13]<-"Night hours"
sensdataff=subset(sensdataff,select=-c(Hour,Weekdays))
sensdataff <- sensdataff[!is.na(sensdataff$Typology), ]
unique(sensdataff$Typology)
# Plot
sensdataff$PM2.5 <- as.numeric(sensdataff$PM2.5)
sensdataff <- sensdataff[!is.infinite(sensdataff$PM2.5) & !is.na(sensdataff$PM2.5), ]
summary(sensdataff)
# Boxplot pour 'Season'
P1 <- ggplot(sensdataff, aes(x = Typology, y = PM2.5, color = Season)) +
geom_boxplot() +
labs(y = "PM2.5 (µg/m³)") +
scale_color_manual(values = c("Winter" = "#0000CC", "Spring" = "#66CC00", "Summer" = "#FFCC33", "Fall" = "#CC0000")) +
theme_minimal()
# Boxplot pour 'DayType'
P2 <- ggplot(sensdataff, aes(x = Typology, y = PM2.5, color = DayType)) +
geom_boxplot() +
labs(y = "PM2.5 (µg/m³)") +
scale_color_manual(values = c("Weekday" = "#0000CC", "Weekend" = "#66CC00")) +
theme_minimal()
# Boxplot pour 'Periods'
P3 <- ggplot(sensdataff, aes(x = Typology, y = PM2.5, color = Periods)) +
geom_boxplot() +
labs(y = "PM2.5 (µg/m³)") +
scale_color_manual(values = c("Night hours" = "#0000CC", "Off-peak hours" = "#66CC00", "Traffic hours" = "#FFCC33", "Transition periods" = "#CC0000")) +
theme_minimal()
png(filename = file.path(path_figures_general, paste0("03_", location_name, "_sensors_boxplots_typo_season_day_hour_final_v3.png")), width = 800, height = 700)
grid.arrange(P1, P2, P3, ncol = 1)
dev.off()
# "Season"
P4 <- ggplot(sensdataff, aes(x = Typology, y = PM2.5, color = Season)) +
geom_boxplot() +
labs(y = "PM2.5 (µg/m³)", title = "PM2.5 selon la saison") +
scale_y_log10() +
scale_color_manual(values = c("Winter" = "#0000CC", "Spring" = "#66CC00",
"Summer" = "#FFCC33", "Fall" = "#CC0000")) +
theme_minimal()
# "DayType"
P5 <- ggplot(sensdataff, aes(x = Typology, y = PM2.5, color = DayType)) +
geom_boxplot() +
labs(y = "PM2.5 (µg/m³)", title = "PM2.5 selon le type de jour") +
scale_y_log10() +
scale_color_manual(values = c("Weekday" = "#0000CC", "Weekend" = "#66CC00")) +
theme_minimal()
# "Periods"
P6 <- ggplot(sensdataff, aes(x = Typology, y = PM2.5, color = Periods)) +
geom_boxplot() +
labs(y = "PM2.5 (µg/m³)", title = "PM2.5 selon les périodes horaires") +
scale_y_log10() +
scale_color_manual(values = c("Night hours" = "#0000CC", "Off-peak hours" = "#66CC00",
"Traffic hours" = "#FFCC33", "Transition periods" = "#CC0000")) +
theme_minimal()
png(filename = file.path(path_figures_general, paste0("03_", location_name, "_boxplots_logScale_typo_season_day_hour.png")),
width = 800, height = 700)
gridExtra::grid.arrange(P4, P5, P6, ncol = 1)
dev.off()
######################################
#          CLASSIFICATION            #
######################################
# Classification considering season only => 4*4 = 16 groups
Group <- rep("group",length(sensdataff[,1]))
sensdataff$Group=Group
# Create groups
Groups <- crossing(var1 = sensdataff$Typology, var2 = sensdataff$Season, var3=sensdataff$Clust ,var4 = sensdataff$DayType, var5 = sensdataff$Periods)
for (ngroup in 1:(dim(Groups)[1])){
group_name=eval(paste0("G",ngroup))
igroup = Groups[ngroup,]
typo=igroup$var1
season=igroup$var2
clust=igroup$var3
daytype=igroup$var4
periods=igroup$var5
idx=which(sensdataff$Typology==typo & sensdataff$Season==season
& sensdataff$Clust==clust & sensdataff$DayType==daytype & sensdataff$Periods==periods)
sensdataff$Group[idx]<-group_name
}
tmp=subset(sensdataff,select=c(Group))
tmp$Count=rep(1,length(tmp[,1]))
stat_group = aggregate(. ~ Group, tmp, function(x) sum(x, na.rm=TRUE), na.action = na.pass)
#####################################
#            SAVE DATA              #
#####################################
LCS_df_all_clean_groups <- sensdataff
save(LCS_df_all_clean_groups, file = file_LCS_df_all_clean_groups_Rda)
rm(list = ls())
# Charger le fichier de configuration global
setwd("C:/Users/diallo/OneDrive - INERIS/Documents/Ineris1/ALT_SensEURCity")
source("00_paths_and_setting.R")
## List of packages to install
Packages <- c("openair")
do.call("library", as.list("openair"))
# Import libraries
library(dplyr)
library(data.table)
library(chron)
library(ggplot2)
library(stats)
library(RColorBrewer)
library(stringr)
library(sf) # Chargement de la bibliothèque pour la manipulation spatiale
library(sp)
library(fields)
library(tidyr)
rm(list = ls())
# Charger le fichier de configuration global
setwd("C:/Users/diallo/OneDrive - INERIS/Documents/Ineris1/ALT_SensEURCity")
source("00_paths_and_setting.R")
# Import libraries
library(raster)
library(sf)
library(RColorBrewer)
library(fields)
library(ggplot2)
library(dplyr)
library(data.table)
library(chron)
library(optimization)
library(Rcpp)
library(Rcpp)
library(Rcpplibrary(optimization)
library(Rcpp)
library(Rcpp)
library(optimization)
library(pracma)
#####################################
#            READ DATA              #
#####################################
print("READ REF AND SENSOR DATA")
# Load .Rda
load(file_LCS_df_all_clean_groups_Rda)
# Init var
nbr_groups=length(unique(LCS_df_all_clean_groups$Group))
group_name=unique(LCS_df_all_clean_groups$Group)
dataout <- c()
for (i in 1:nbr_groups){ # Loop over groups
print(i)
Group=group_name[i]
df <- LCS_df_all_clean_groups[which(LCS_df_all_clean_groups$Group==Group),]
df_group=paste0(unique(df$Typology)," ",unique(df$Season)," ",unique(df$Clust))
print(df_group)
#####################################
#1 Square root transormation
PM25 <- df$PM2.5
xc <- sqrt(PM25 + (1-min(PM25)))
if (length(xc[!duplicated(xc)]) > 1 & length(xc) > 2) {
df1=df
df1$PM2.5=xc
#####################################
#2 Mean and standard deviation calculation removing the ith observation
mkj_all=c()
skj_all=c()
for (j in 1:length(xc)){
mkj=mean(xc[-j])
skj=sd(xc[-j])
mkj_all=rbind(mkj_all,mkj)
skj_all=rbind(skj_all,skj)
}
#####################################
#3 Optimization of the log likelihood function
# Init var
mkj_all=as.vector(mkj_all) # meanof the truncated normal distribution
skj_all=as.vector(skj_all) # standard deviation of the truncated normal distribution
tk=c(); nk=c() # sandard deviation and mean of the underlying normal distribution to be caluclated by the optimization
z=3 # confidence level
outliers = rep("Accepted value",length(mkj_all))
# Estimate interval for each observation
for (kk in 1:length(mkj_all)){
# Likelihood function
L <- function(x){
term1 = (1/(x[1]*sqrt(2*pi))) * (exp((-1/2)*((xc[kk]-x[2])/x[1])**2))
term2 = (1/2) * (1 + erf((1-x[2])/(x[1]*sqrt(2))))
y <- sum(log(term1)-(log(x[1]*(1-term2))))
}
# Define parameters
x=c(skj_all[kk],mkj_all[kk])
# Init parameter bounds
skj_all_lower=skj_all[kk]*1; skj_all_upper=skj_all[kk]*50
mkj_all_lower=mkj_all[kk]*0; mkj_all_upper=mkj_all[kk]*1
# Optimization with Nelder-Mead
#L_nm = optim_nm(L, start=c(tkj_all,nkj_all), trace=TRUE)#,exit=10000)
#L_nm = optim_nm(L, k=2, trace=TRUE)#,exit=10000)
# Optimization with Simulated Annealing
L_sa = optim_sa(L, start=c(x[1],x[2]),lower=c(skj_all_lower,mkj_all_lower),upper=c(skj_all_upper,mkj_all_upper),trace=TRUE)
# Calculate interval
tk[kk]=L_sa$par[1]
nk[kk]=L_sa$par[2]
upper = nk[kk]+z*tk[kk]
lower = nk[kk]-z*tk[kk]
if (lower<0){ lower=0 }
# Define outliers
if (xc[kk]<lower | xc[kk]>upper){ outliers[kk]="outlier"}#; print(paste0("outlier in", kk, "=> for ", xc, " upper=",upper," and lower=",lower))}
#print(xc[kk])
#print(upper)
#print(lower)
#print(outliers[kk])
}
#TMP
#x=c(skj_all,mkj_all)
#skj_all_lower=skj_all*1; skj_all_upper=skj_all*5
#mkj_all_lower=mkj_all*0; mkj_all_upper=mkj_all*2
#L_sa = optim_sa(L, start=c(x[,1],x[,2]),lower=c(skj_all_lower,mkj_all_lower),upper=c(skj_all_upper,mkj_all_upper),trace=TRUE)
#upper = mkj_all+z*skj_all
#lower = mkj_all-z*skj_all
#idx_out=which(xc<lower | xc >upper)
#outliers <- rep("Accepted value",length(df[,1]))
#df$outliers=outliers
#df$outliers[idx_out]="Outlier"
#5 Backtransformation
PM25c=(xc**2)-(min(xc))
#6 Assign outliers flag
df$outliers=outliers
ID_out=unique(df[which(df$outliers=="Outlier"),1])
df_out=df[which(df$ID %in% ID_out),]
df$outliers=as.factor(df$outliers)
# Plot
png(filename=file.path(path_figures_outliers, paste0("_04_Outliers_",Group,".png")), width=1000, height=600, type="cairo",bg = "white")
p4 <- ggplot(df, aes(x=datetime,y=PM25)) + geom_point(aes(color=outliers)) +
#xlim(c(0, 15))+#ylim(c(0, 3e6))+
scale_color_manual(values=c("black", "red"))+
labs(title=paste0(Group,": ",df_group),x="",y=bquote(.(pollutant_name) ~ (mu*g/m^3)))+
theme_bw()+
theme_minimal()+
theme(plot.title = element_text(size=24),
axis.text=element_text(size=24),
axis.title=element_text(size=24),
legend.text = element_text(size =24),
legend.title = element_blank(),
legend.spacing.x = unit(0.3, 'cm'),
legend.position= "right")
print(p4)
dev.off()
#7 Concatenate df
if (nbr_groups == 1){
dataout <- df
}else{
dataout <- rbind(dataout,df)
}
#df
}
}
rm(list = ls())
# Charger le fichier de configuration global
source("00_paths_and_setting.R")
rm(list = ls())
# Charger le fichier de configuration global
source("00_paths_and_setting.R")
# Charger les bibliothèques nécessaires
library(data.table)
library(openair)
library(tidyverse)
# Utiliser le répertoire défini dans le fichier de configuration
dataset_directory <- path_dataset
# Importation de fichiers de données
file_list <- list.files(path = dataset_directory, pattern = "*.csv", full.names = TRUE)
file_list <- file_list[!grepl("ANT_REF_R801_Fidas_UTC", file_list)]
start_date <- as.POSIXct("2020-06-18 01:00:00" , tz="UTC")
end_date <- as.POSIXct("2021-02-16 01:00:00" , tz="UTC")
#                                      ###        OPC         ###
#                                      ###                    ###
#                                      ##########################
#                                      ##########################
#
#
#
#
#
# # Initialiser une liste pour stocker les data frames OPC
data_list <- list()
# colonne à garder
columns_to_keep_OPCN3 <- c("date", "latitude", "longitude", "Location.ID", "OPCN3PM10" , "OPCN3PM25")
# Boucle pour lire chaque fichier CSV de capteur, effectuer les modifications et stocker dans la liste
for (file in file_list) {
# Lire le fichier CSV
data <- fread(file)
# Suppression des lignes en dehors de l'intervalle de temps d'intérêt
data[, date := as.POSIXct(date, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")]
data <- data[data$date >= start_date & data$date <= end_date, ]
# Suppression des colonnes non désirées (ajustez en fonction des colonnes qu'on veut garder)
data <- data[, ..columns_to_keep_OPCN3]
# Agrégation horaire des données
data_hourly <- timeAverage(data, avg.time = "hour", statistic = "mean", type = "Location.ID")
# Ajouter le data frame modifié à la liste
data_list[[basename(file)]] <- data_hourly
}
print(data_list[[1]])
#
# Fusionner tous les data frames en un seul
LCS_df_all <- do.call(rbind, data_list)
#
#créer la colonne ID en utilisant les rownames
LCS_df_all$ID <- gsub("\\.csv.*", "", rownames(LCS_df_all))
LCS_df_all <- LCS_df_all %>% filter(Location.ID != "")
LCS_df_all$Location.ID <- as.character(LCS_df_all$Location.ID)
LCS_df_all$Location.ID[LCS_df_all$Location.ID == "ANT_TRA_KIPD"] <- "ANT_URB_KIPD"
unique(LCS_df_all$Location.ID)
library(dplyr)
LCS_df_all <- LCS_df_all %>%
select(ID, date, latitude, longitude, Location.ID, OPCN3PM10, OPCN3PM25)
#                                           ##########################
#                                           ###                    ###
#                                           ###        PMS         ###
#                                           ###                    ###
#                                           ##########################
#                                           ##########################
#
#
#
# Initialisation d'une liste pour stocker les dataframes PMS
data_list_PMS <- list()
# colonne à garder
columns_to_keep_PMS <- c("date", "latitude", "longitude", "Location.ID", "5310CAT" , "5325CAT")
for (file in file_list) {
data_PMS <- fread(file)
data_PMS[, date := as.POSIXct(date, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")]
data_PMS <- data_PMS[data_PMS$date >= start_date & data_PMS$date <= end_date, ]
data_PMS <- data_PMS[, ..columns_to_keep_PMS]
# Agrégation horaire des données
data_hourly_PMS <- timeAverage(data_PMS, avg.time = "hour", statistic = "mean" , type="Location.ID")
# Ajouter le data frame modifié à la liste
data_list_PMS[[basename(file)]] <- data_hourly_PMS
}
library(dplyr)
LCS_df_all <- LCS_df_all %>%
select(ID, date, latitude, longitude, Location.ID, OPCN3PM10, OPCN3PM25)
rm(list = ls())
# Charger le fichier de configuration global
source("00_paths_and_setting.R")
# Charger les bibliothèques nécessaires
library(data.table)
library(openair)
library(tidyverse)
# Utiliser le répertoire défini dans le fichier de configuration
dataset_directory <- path_dataset
# Importation de fichiers de données
file_list <- list.files(path = dataset_directory, pattern = "*.csv", full.names = TRUE)
file_list <- file_list[!grepl("ANT_REF_R801_Fidas_UTC", file_list)]
start_date <- as.POSIXct("2020-06-18 01:00:00" , tz="UTC")
end_date <- as.POSIXct("2021-02-16 01:00:00" , tz="UTC")
#                                      ###        OPC         ###
#                                      ###                    ###
#                                      ##########################
#                                      ##########################
#
#
#
#
#
# # Initialiser une liste pour stocker les data frames OPC
data_list <- list()
# colonne à garder
columns_to_keep_OPCN3 <- c("date", "latitude", "longitude", "Location.ID", "OPCN3PM10" , "OPCN3PM25")
# Boucle pour lire chaque fichier CSV de capteur, effectuer les modifications et stocker dans la liste
for (file in file_list) {
# Lire le fichier CSV
data <- fread(file)
# Suppression des lignes en dehors de l'intervalle de temps d'intérêt
data[, date := as.POSIXct(date, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")]
data <- data[data$date >= start_date & data$date <= end_date, ]
# Suppression des colonnes non désirées (ajustez en fonction des colonnes qu'on veut garder)
data <- data[, ..columns_to_keep_OPCN3]
# Agrégation horaire des données
data_hourly <- timeAverage(data, avg.time = "hour", statistic = "mean", type = "Location.ID")
# Ajouter le data frame modifié à la liste
data_list[[basename(file)]] <- data_hourly
}
print(data_list[[1]])
#
# Fusionner tous les data frames en un seul
LCS_df_all <- do.call(rbind, data_list)
#
#créer la colonne ID en utilisant les rownames
LCS_df_all$ID <- gsub("\\.csv.*", "", rownames(LCS_df_all))
LCS_df_all <- LCS_df_all %>% filter(Location.ID != "")
LCS_df_all$Location.ID <- as.character(LCS_df_all$Location.ID)
LCS_df_all$Location.ID[LCS_df_all$Location.ID == "ANT_TRA_KIPD"] <- "ANT_URB_KIPD"
unique(LCS_df_all$Location.ID)
library(dplyr)
LCS_df_all <- LCS_df_all %>%
select(ID, date, latitude, longitude, Location.ID, OPCN3PM10, OPCN3PM25)
